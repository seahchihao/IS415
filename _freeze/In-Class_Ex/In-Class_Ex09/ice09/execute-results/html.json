{
  "hash": "c3f2c124b447e5eae27762dbbf66f6b4",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"In-Class Exercise 07\"\nauthor: \"Seah Chi Hao\"\ndate: 2024-10-21\ndate-modified: \"last-modified\"\nexecute:\n  eval: true\n  echo: true\n  freeze: true\n  output: true\n  warning: false\n---\n\n\n\n> Some learning from last lesson:\nLook deeply into the data and is there assuptions or outliers (e.g. more data due to higher population), and how to counter these to ensure a more interesting analysis? (i.e. take data per capita, to find out the true distribution of data, not affected by poplation size)\nStadardisation techniques can also be used, depending on context. (z-score, min-max, decimal-scaling)\n\nNo linear relationship != no relationship\n\nBelow is In-Class Ex09\n\n---\n\n## 1.0 Installing and Loading the R Packages\n\nInstall the following packages:\n\n- spdep\n- sp\n- tmap\n- sf\n- ClustGeo\n- cluster\n- factoextra\n- NbClust\n- tidyverse\n- GGally\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npacman::p_load(spdep, sp, tmap, sf, ClustGeo, \n               cluster, factoextra, NbClust,\n               tidyverse, GGally)\n```\n:::\n\n\n\n## 2.0 Preparing the Data\n\n-   Import the relevant data (intermediate data derived from Hands-On).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf <- read_rds(\"data/rds/shan_sf.rds\")\nshan_ict <- read_rds(\"data/rds/shan_ict.rds\")\nshan_sf_cluster <- read_rds(\"data/rds/shan_sf_cluster.rds\")\n```\n:::\n\n\n\n## 3.0 Conventional Hierarchical Clustering\n\n### 3.1 Hierarchical Clustering\n\n\n::: {.cell}\n\n```{.r .cell-code}\nproxmat <- dist(shan_ict, method = 'euclidean') \n#able to have the option to select certain columns/variables in the data\n#do print(proxmat) in the console to see the output // for checking purpose\nhclust_ward <- hclust(proxmat, method = 'ward.D')\n#hclust_ward is an hclust object // check with class(hclust_wards)\ngroups <- as.factor(cutree(hclust_ward, k=6))\n#for clustering always min 3\n```\n:::\n\n\n\n### 3.2 Append to the geospatial data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan_sf_cluster <- cbind(shan_sf,\n                         as.matrix(groups)) %>%\n  rename(`CLUSTER` = `as.matrix.groups.`) %>% #use ` not ' is there any reason? // the . is very impt\n  select(-c(3:4, 7:9)) %>%\n  rename(TS = TS.x)\n```\n:::\n\n\n\n### 3.3 The dendrogram\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(hclust_ward, cex = 0.6)\nrect.hclust(hclust_ward, k = 6, border = 2:5)\n```\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n### 3.4 Cluster map\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqtm(shan_sf_cluster, \"CLUSTER\")\n```\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#R only has 16 colours on default, beyond that we have to manually create a new colour\n```\n:::\n\n\n\n## 4.0 Spatially Contrained Clustering: SKATER method\nSKATER (Spatial 'K\"luster Analysis by Tree Edge Removal algorithm) -> get minimum spanning tree\n\n### 4.1 Step 1: Computing nearest neighbours\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan.nb <- poly2nb(shan_sf)\nsummary(shan.nb)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n```\n\n\n:::\n:::\n\n\n\n### 4.2 Step 2: Visualising the neighbours\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(st_geometry(shan_sf),\n     border=grey(.5))\n```\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n```{.r .cell-code}\npts <- st_coordinates((st_centroid(shan_sf)))\nplot(shan.nb,\n     pts,\n     col=\"blue\",\n     ass=TRUE)\n```\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-8-2.png){width=672}\n:::\n:::\n\n\n\n### 4.3 Step 3: Computing minimum spanning tree\n\n#### 4.3.1 Calculate edge costs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlcosts <- nbcosts(shan.nb, shan_ict)\n```\n:::\n\n\n\n#### 4.3.2 Incorporating theses costs into a weights object\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan.w <- nb2listw(shan.nb,\n                   lcosts,\n                   style = \"B\") #hardcode the binary // not everything allow user to change\nsummary(shan.w)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nCharacteristics of weights list object:\nNeighbour list object:\nNumber of regions: 55 \nNumber of nonzero links: 264 \nPercentage nonzero weights: 8.727273 \nAverage number of links: 4.8 \nLink number distribution:\n\n 2  3  4  5  6  7  8  9 \n 5  9  7 21  4  3  5  1 \n5 least connected regions:\n3 5 7 9 47 with 2 links\n1 most connected region:\n8 with 9 links\n\nWeights style: B \nWeights constants summary:\n   n   nn       S0       S1        S2\nB 55 3025 76267.65 58260785 522016004\n```\n\n\n:::\n:::\n\n\n\n#### 4.3.3 Computing MST\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshan.mst <- mstree(shan.w)\n```\n:::\n\n\n\n#### 4.3.4 Visualising MST\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(st_geometry(shan_sf),\n     border=gray(.5))\nplot.mst(shan.mst,\n         pts,\n         col=\"blue\",\n         cex.lab=0.7,\n         cex.circles=0.005,\n         add=TRUE)\n```\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n### 4.4 Getting the skater tree\n\n\n::: {.cell}\n\n```{.r .cell-code}\nskater.clust6 <- skater(edges = shan.mst[,1:2],\n                        data = shan_ict,\n                        method = \"euclidean\",\n                        ncuts = 5) #note that n is 5 for cluster 6 \n                                  #this is because the code start from 0 (we can do n-1 where n is the user input to not confuse the user)\n```\n:::\n\n\n\nPlot the SKATER Tree\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(st_geometry(shan_sf), #for outline using st_geometry would be good\n     border=gray(.5))\nplot(skater.clust6,\n     pts,\n     cex.lab=.7,\n     groups.colours=c(\"red\",\"green\",\"blue\",\"brown\",\"pink\"),\n     cex.circles=0.005,\n     add=TRUE) #this line means plot this part of the code over the previous code (the outline)\n```\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-14-1.png){width=672}\n:::\n:::\n\n\n### 4.5 Visualising the clusters in choropleth map\n\n\n::: {.cell}\n\n```{.r .cell-code}\ngroups_mat <- as.matrix(skater.clust6$groups)\nshan_sf_spatialcluster <- cbind(shan_sf_cluster, as.factor(groups_mat)) %>% #as.factor organise it ascending from 1 to 6\n  rename(`skater_CLUSTER` = `as.factor.groups_mat.`)\nqtm(shan_sf_spatialcluster, \"skater_CLUSTER\")\n```\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-15-1.png){width=672}\n:::\n:::\n\n\n\n## 5.0 Spatially Contrained Clustering: ClustGeo method\n\n### 5.1 Computing spatial distance matrix\nIn the code chunk below, `st_distance()` of **sf** package is used to compute the distance matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndist <- st_distance(shan_sf, shan_sf)\ndistmat <- as.dist(dist)\n```\n:::\n\n\n\n### 5.2 The cluster graphs\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncr <- choicealpha(proxmat, distmat,\n                  range.alpha = seq(0, 1, 0.1),\n                  K=6, graph = TRUE)\n```\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-17-2.png){width=672}\n:::\n:::\n\n\n> Note:\nOutput 2 graphs: one absoulte and one standardised. We are usually more interest in the graph with the absolute value.\n\n### 5.3 Saving clustGeo output\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclustG <- hclustgeo(proxmat, distmat, alpha = 0.2)\ngroups <- as.factor(cutree(clustG, k=6))\nshan_sf_clustGeo <- cbind(shan_sf,\n                          as.matrix(groups)) %>%\n  rename(`clustGeo` = `as.matrix.groups.`)\n```\n:::\n\n\n\n### 5.4 Visualising the clustGeo map\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqtm(shan_sf_clustGeo, \"clustGeo\")\n```\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n## 6.0 Comparing cluster maps\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntmap_mode(\"plot\")\nmap1 <- qtm(shan_sf_cluster, \"CLUSTER\")\n    \nmap2 <- qtm(shan_sf_spatialcluster, \"skater_CLUSTER\")\n\nmap3 <- qtm(shan_sf_clustGeo, \"clustGeo\")\n\ntmap_arrange(map1, map2, map3, ncol = 3)\n```\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-20-1.png){width=672}\n:::\n:::\n\n\n>Note:\nMethod (SKATER or clustGeo) to use depends\nClustering is multi-variate analysis, compared to single-variate analysis of LISA and G* I of Take-Home 2\n\n## 7.0 Characterising the clusters\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggparcoord(data = shan_sf_clustGeo,\n           columns = c(17:21),\n           scale = \"globalminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE,\n           title = \"Multiple Parallel Coordinates Plots of ICT Variables by Cluster\") +\n  facet_grid(~ clustGeo) +\n  theme(axis.test.x = element_text(angle = 30))\n```\n\n::: {.cell-output-display}\n![](ice09_files/figure-html/unnamed-chunk-21-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "ice09_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}